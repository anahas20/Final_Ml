{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import twitter, re, datetime, pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Prediction\n",
    "\n",
    "- The intention is the ability to identify the probability where these information originated from or who is more likely to produce that content. The project explores the problem on a smaller scale between two opposing sides. Also, it implements the possibility to explore this practice on a larger scale analyzing bigger entities like governments and organization, and to be able to distinguish if particular pieces of information are produced a particular side to prevent information fraud, deceit, or deception\n",
    "\n",
    "- The project will use Python wrapper by Twitter Application Programming Interface (API) to mine tweets from the selected users, in order to create a dataframe. Then will use a TfidfVectorizer (natural language processing) from sklearn to analyze the tweets from each user. After cleaning the texts and exploring it, multiple ML algorithms will be used like Linear regression , Logistic Regression, SVM , Decision trees , and other applicable ones.\n",
    "\n",
    "- It will be later trained and fitted for optimization, and then evaluated through a confusion matrix. Finally, create a function to take a specific row from the dataframe to predict to which user it belongs, witha prediction result (either candidate A or B).\n",
    "\n",
    "#### [1] Setup Twitter API\n",
    "#### [2] Establishing Class\n",
    "#### [3] Create Training Data\n",
    "#### [4] Using Textacy to pre-process tweets\n",
    "#### [5] Building Model\n",
    "#### [6] Highest probablity tweet and Prediction module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# [1] Setup Twitter API\n",
    "\n",
    "##### This will be done on the following steps\n",
    "- 1. Setup API keys\n",
    "- 2. Test function by using **@JoeBiden** account\n",
    "- 3. Print results\n",
    "- 4. Setup TweetMiner function\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter.api.Api"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from Mike Taylor A Python wrapper around the Twitter API.\n",
    "# https://github.com/bear/python-twitter\n",
    "\n",
    "twitter_keys = {\n",
    "    'consumer_key':        'L4sziHBqV4VUIfKezbos0JMVl',\n",
    "    'consumer_secret':     'lJau6R7GIHFwoGR5wB3PlLQPXBChwzJFJ9WGXXtazcDSA1Vb1X',\n",
    "    'access_token_key':    '941359629606539264-05XcmQfdwMXTbPNWS3r7cZThvbQBxCK',\n",
    "    'access_token_secret': 'VdE3VJVk6oxbohQGcw7WYA5Tg4Sr8kW9duTO1wxmB6qXk'\n",
    "}\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   twitter_keys['consumer_key'],\n",
    "    consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "    access_token_key     =   twitter_keys['access_token_key'],\n",
    "    access_token_secret  =   twitter_keys['access_token_secret'],\n",
    "    tweet_mode = 'extended'\n",
    ")\n",
    "\n",
    "# double check if the API is working\n",
    "\n",
    "type(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Dec 08 13:56:00 +0000 2020',\n",
       " 'favorite_count': 14348,\n",
       " 'full_text': 'There has never been anyone more qualified to be Treasury Secretary than Janet Yellen. Period.\\n\\nI trust her knowledge and look forward to working with her to build our economy back better. https://t.co/M7E31FPimX',\n",
       " 'hashtags': [],\n",
       " 'id': 1336308549262200832,\n",
       " 'id_str': '1336308549262200832',\n",
       " 'lang': 'en',\n",
       " 'quoted_status': {'created_at': 'Mon Dec 07 22:14:48 +0000 2020',\n",
       "  'favorite_count': 6657,\n",
       "  'full_text': 'Our mission is to restore economic prosperity and financial stability.\\n\\nWe’ll do that by pursuing an investment agenda to rebuild our infrastructure, create better jobs, advance racial equity, and fight the climate crisis. https://t.co/IDUKBlcFDs',\n",
       "  'hashtags': [],\n",
       "  'id': 1336071689583665152,\n",
       "  'id_str': '1336071689583665152',\n",
       "  'lang': 'en',\n",
       "  'media': [{'display_url': 'pic.twitter.com/IDUKBlcFDs',\n",
       "    'expanded_url': 'https://twitter.com/JanetYellen/status/1336071689583665152/video/1',\n",
       "    'id': 1336070018761711619,\n",
       "    'media_url': 'http://pbs.twimg.com/media/EoqtwFNWMAAv_Pn.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/EoqtwFNWMAAv_Pn.jpg',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'small': {'w': 680, 'h': 680, 'resize': 'fit'},\n",
       "     'medium': {'w': 720, 'h': 720, 'resize': 'fit'},\n",
       "     'large': {'w': 720, 'h': 720, 'resize': 'fit'}},\n",
       "    'type': 'video',\n",
       "    'url': 'https://t.co/IDUKBlcFDs',\n",
       "    'video_info': {'aspect_ratio': [1, 1],\n",
       "     'duration_millis': 104146,\n",
       "     'variants': [{'content_type': 'application/x-mpegURL',\n",
       "       'url': 'https://video.twimg.com/amplify_video/1336070018761711619/pl/_6qLVLZqddd2E7zV.m3u8?tag=13'},\n",
       "      {'bitrate': 832000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/amplify_video/1336070018761711619/vid/480x480/sqYQZzyFgBZ6BnSE.mp4?tag=13'},\n",
       "      {'bitrate': 1280000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/amplify_video/1336070018761711619/vid/720x720/Mb6Dbf5KnIu66j5L.mp4?tag=13'},\n",
       "      {'bitrate': 432000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/amplify_video/1336070018761711619/vid/320x320/r2d2B5ijBg_NpZHw.mp4?tag=13'}]}}],\n",
       "  'retweet_count': 1076,\n",
       "  'source': '<a href=\"https://studio.twitter.com\" rel=\"nofollow\">Twitter Media Studio</a>',\n",
       "  'urls': [],\n",
       "  'user': {'created_at': 'Sun Nov 29 22:12:26 +0000 2020',\n",
       "   'default_profile': True,\n",
       "   'description': 'Current nominee for Treasury Secretary. Former Fed Chair. Always an economist.',\n",
       "   'followers_count': 101222,\n",
       "   'friends_count': 4,\n",
       "   'id': 1333171793201225728,\n",
       "   'id_str': '1333171793201225728',\n",
       "   'listed_count': 747,\n",
       "   'name': 'Janet Yellen',\n",
       "   'profile_background_color': 'F5F8FA',\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1333171793201225728/1606747419',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1333421043772375043/N3Z22RJ1_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1333421043772375043/N3Z22RJ1_normal.jpg',\n",
       "   'profile_link_color': '1DA1F2',\n",
       "   'profile_sidebar_border_color': 'C0DEED',\n",
       "   'profile_sidebar_fill_color': 'DDEEF6',\n",
       "   'profile_text_color': '333333',\n",
       "   'profile_use_background_image': True,\n",
       "   'screen_name': 'JanetYellen',\n",
       "   'statuses_count': 5,\n",
       "   'url': 'https://t.co/P5iAcPoHmj',\n",
       "   'verified': True},\n",
       "  'user_mentions': []},\n",
       " 'quoted_status_id': 1336071689583665152,\n",
       " 'quoted_status_id_str': '1336071689583665152',\n",
       " 'retweet_count': 1328,\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       " 'urls': [{'expanded_url': 'https://twitter.com/JanetYellen/status/1336071689583665152',\n",
       "   'url': 'https://t.co/M7E31FPimX'}],\n",
       " 'user': {'created_at': 'Sun Mar 11 17:51:24 +0000 2007',\n",
       "  'description': 'President-elect, husband to @DrBiden, proud father & grandfather. Ready to build back better for all Americans.',\n",
       "  'favourites_count': 20,\n",
       "  'followers_count': 20798582,\n",
       "  'friends_count': 32,\n",
       "  'id': 939091,\n",
       "  'id_str': '939091',\n",
       "  'listed_count': 30080,\n",
       "  'location': 'Wilmington, DE',\n",
       "  'name': 'Joe Biden',\n",
       "  'profile_background_color': '565959',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/939091/1604514209',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1308769664240160770/AfgzWVE7_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1308769664240160770/AfgzWVE7_normal.jpg',\n",
       "  'profile_link_color': '233F94',\n",
       "  'profile_sidebar_border_color': 'FFFFFF',\n",
       "  'profile_sidebar_fill_color': 'EBEBFF',\n",
       "  'profile_text_color': '323232',\n",
       "  'profile_use_background_image': True,\n",
       "  'screen_name': 'JoeBiden',\n",
       "  'statuses_count': 6919,\n",
       "  'url': 'https://t.co/UClrPuJpyZ',\n",
       "  'verified': True},\n",
       " 'user_mentions': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a limit set on the count by Twitter API, can't exceed 200\n",
    "# Link with the highlighted text\n",
    "# https://tinyurl.com/y3cx3m6a\n",
    "\n",
    "# A first test trial to check everything is working. We are using Joe Biden's Account\n",
    "# https://twitter.com/JoeBiden\n",
    "\n",
    "x = api.GetUserTimeline(screen_name=\"JoeBiden\", count=5, include_rts=False)\n",
    "x = [_.AsDict() for _ in x]\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336308549262200832\n",
      "There has never been anyone more qualified to be Treasury Secretary than Janet Yellen. Period.\n",
      "\n",
      "I trust her knowledge and look forward to working with her to build our economy back better. https://t.co/M7E31FPimX\n",
      "____________________________\n",
      "1336128110203449345\n",
      "Paul Sarbanes and I served together on the Foreign Relations Committee for 30 years. There was no one sharper, more committed, or with firmer principles. And he, too, returned to his family nearly every night. They meant the world to him.\n",
      "\n",
      "Rest In Peace, Paul. https://t.co/tzekdNb74b\n",
      "____________________________\n",
      "1336054123163234304\n",
      "Today, we remember those we lost at Pearl Harbor 79 years ago — and we salute those who answered duty’s call with strength and courage. Our nation owes an incredible debt to those who have served and must ensure they and their families receive the care they’ve earned.\n",
      "____________________________\n",
      "1336003791183818753\n",
      "Dr. Fauci isn't just one of our foremost experts on combating viruses—he is a good man and a tireless public servant. He has served six presidents and led us through some of our toughest challenges.\n",
      "\n",
      "Our administration, and our country, will be stronger because of his guidance.\n",
      "____________________________\n",
      "1335989451584118790\n",
      "Georgia — Today is your last day to register to vote in the January runoff. \n",
      "\n",
      "Head to https://t.co/RIJ1L4juwB to get registered, and let’s flip the Senate.\n",
      "____________________________\n"
     ]
    }
   ],
   "source": [
    "# As you can see we get a list of information about each tweet\n",
    "# We want to print the tweet text and tweet ID\n",
    "\n",
    "\n",
    "for element in x:\n",
    "    print(element['id'])\n",
    "    print(element['full_text'])\n",
    "    print('____________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1336308549262200832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could call the Tweet ID\n",
    "\n",
    "print(type(x[0]))\n",
    "x[0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TweetMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TweetMiner function from Bhishan Poudel and Mike Roman\n",
    "\n",
    "class TweetMiner(object):\n",
    "\n",
    "    \n",
    "    def __init__(self, api, result_limit = 200):\n",
    "        \n",
    "        self.api = api        \n",
    "        self.result_limit = result_limit\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user=\"Joebiden\", mine_retweets=False, max_pages=20):\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1, include_rts=mine_retweets)\n",
    "                statuses = [ _.AsDict() for _ in statuses]\n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, include_rts=mine_retweets)\n",
    "                statuses = [_.AsDict() for _ in statuses]\n",
    "                \n",
    "            for item in statuses:\n",
    "                # Using try except here.\n",
    "                # When retweets = 0 we get an error (GetUserTimeline fails to create a key, 'retweet_count')\n",
    "                try:\n",
    "                    mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   item['retweet_count'],\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "                    }\n",
    "                \n",
    "                except:\n",
    "                        mined = {\n",
    "                        'tweet_id':        item['id'],\n",
    "                        'handle':          item['user']['screen_name'],\n",
    "                        'retweet_count':   0,\n",
    "                        'text':            item['full_text'],\n",
    "                        'mined_at':        datetime.datetime.now(),\n",
    "                        'created_at':      item['created_at'],\n",
    "                    }\n",
    "                \n",
    "                last_tweet_id = item['id']\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Establishing Class\n",
    "### ---------------------------\n",
    "##### This will be done on the following steps \n",
    "- 1. Setup result limit (200) on TweetMiner\n",
    "- 2. Mine **@JoeBiden** tweets\n",
    "- 3. Mine **@realDonaldTrump** tweets\n",
    "- 4. Print results\n",
    "- 5. Convert output tweets to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a limit of 200 - Complying with rate limit request\n",
    "\n",
    "miner = TweetMiner(api, result_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the two classes\n",
    "\n",
    "biden = miner.mine_user_tweets(user=\"Joebiden\")\n",
    "donald = miner.mine_user_tweets(user=\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There has never been anyone more qualified to be Treasury Secretary than Janet Yellen. Period.\n",
      "\n",
      "I trust her knowledge and look forward to working with her to build our economy back better. https://t.co/M7E31FPimX\n",
      "---\n",
      "Paul Sarbanes and I served together on the Foreign Relations Committee for 30 years. There was no one sharper, more committed, or with firmer principles. And he, too, returned to his family nearly every night. They meant the world to him.\n",
      "\n",
      "Rest In Peace, Paul. https://t.co/tzekdNb74b\n",
      "---\n",
      "Today, we remember those we lost at Pearl Harbor 79 years ago — and we salute those who answered duty’s call with strength and courage. Our nation owes an incredible debt to those who have served and must ensure they and their families receive the care they’ve earned.\n",
      "---\n",
      "Dr. Fauci isn't just one of our foremost experts on combating viruses—he is a good man and a tireless public servant. He has served six presidents and led us through some of our toughest challenges.\n",
      "\n",
      "Our administration, and our country, will be stronger because of his guidance.\n",
      "---\n",
      "Georgia — Today is your last day to register to vote in the January runoff. \n",
      "\n",
      "Head to https://t.co/RIJ1L4juwB to get registered, and let’s flip the Senate.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Printing the first 5 tweets to see our results for Biden\n",
    "\n",
    "for x in range(5):\n",
    "    print(biden[x]['text'])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And it’s not normal when a sitting Senator is forced to retire because his Arizona poll numbers were so low that he would have come out dead last in the Republican Primary, and had zero chance of winning the general election. Great job Jeff! https://t.co/5kbOQIpstq\n",
      "--\n",
      "I hope House Republicans will vote against the very weak National Defense Authorization Act (NDAA), which I will VETO. Must include a termination of Section 230 (for National Security purposes), preserve our National Monuments, &amp; allow for 5G &amp; troop reductions in foreign lands!\n",
      "--\n",
      "Georgia is watching @BrianKempGA, @GeoffDuncanGA, and @GaSecofState! https://t.co/8R8rH8aV9U\n",
      "--\n",
      "https://t.co/reenwuelHY\n",
      "--\n",
      "THANK YOU GEORGIA! https://t.co/62s0XaiYPI\n",
      "--\n",
      "Georgia Lt. Governor @GeoffDuncanGA is a RINO Never Trumper who got himself elected as LG by falsely claiming to be “pro-Trump”. Too dumb or corrupt to recognize massive evidence of fraud in GA &amp; should be replaced! We need every great Georgian to call him out! #SpecialSession!\n",
      "--\n",
      "“Georgia is not the only state that pushed through these last minute rules changes before the presidential election.” @marthamaccallum  They forgot about our Constitution!\n",
      "--\n",
      "Mail-In rejection rate was minuscule compared to what it used to be. Ken Starr  Meaning that massive numbers of bad votes were pouring in!\n",
      "--\n",
      "State officials were ignorant of the limitations imposed by the Constitution. Ken Starr\n",
      "--\n",
      "“These actions on the part of State Officials, making these changes, were violating the Constitution of the U.S. They were usurping power.” Ken Starr\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Printing the first 10 tweets to see our results for Donald\n",
    "\n",
    "for x in range(10):\n",
    "    print(donald[x]['text'])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Testing to see how the dataframe looks\n",
    "#### Joe Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336308549262200832</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>1328</td>\n",
       "      <td>There has never been anyone more qualified to ...</td>\n",
       "      <td>2020-12-08 09:45:50.544717</td>\n",
       "      <td>Tue Dec 08 13:56:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336128110203449345</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>1976</td>\n",
       "      <td>Paul Sarbanes and I served together on the For...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Tue Dec 08 01:59:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336054123163234304</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>9744</td>\n",
       "      <td>Today, we remember those we lost at Pearl Harb...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Mon Dec 07 21:05:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336003791183818753</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>13261</td>\n",
       "      <td>Dr. Fauci isn't just one of our foremost exper...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Mon Dec 07 17:45:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335989451584118790</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>11806</td>\n",
       "      <td>Georgia — Today is your last day to register t...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Mon Dec 07 16:48:01 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1335964029299224578</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>3883</td>\n",
       "      <td>This team of world-class medical experts and p...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Mon Dec 07 15:07:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1335758425284874240</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>15690</td>\n",
       "      <td>I promise you this: I will spare no effort — o...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Mon Dec 07 01:30:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1335690479351042057</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>6671</td>\n",
       "      <td>The dreams of too many Americans have been def...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Sun Dec 06 21:00:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1335619257376247811</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>9768</td>\n",
       "      <td>With COVID-19 cases rising across the nation, ...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Sun Dec 06 16:17:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1335392513364922370</td>\n",
       "      <td>JoeBiden</td>\n",
       "      <td>9691</td>\n",
       "      <td>I know times are tough, the challenges are dau...</td>\n",
       "      <td>2020-12-08 09:45:50.545715</td>\n",
       "      <td>Sun Dec 06 01:16:00 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    handle  retweet_count  \\\n",
       "0  1336308549262200832  JoeBiden           1328   \n",
       "1  1336128110203449345  JoeBiden           1976   \n",
       "2  1336054123163234304  JoeBiden           9744   \n",
       "3  1336003791183818753  JoeBiden          13261   \n",
       "4  1335989451584118790  JoeBiden          11806   \n",
       "5  1335964029299224578  JoeBiden           3883   \n",
       "6  1335758425284874240  JoeBiden          15690   \n",
       "7  1335690479351042057  JoeBiden           6671   \n",
       "8  1335619257376247811  JoeBiden           9768   \n",
       "9  1335392513364922370  JoeBiden           9691   \n",
       "\n",
       "                                                text  \\\n",
       "0  There has never been anyone more qualified to ...   \n",
       "1  Paul Sarbanes and I served together on the For...   \n",
       "2  Today, we remember those we lost at Pearl Harb...   \n",
       "3  Dr. Fauci isn't just one of our foremost exper...   \n",
       "4  Georgia — Today is your last day to register t...   \n",
       "5  This team of world-class medical experts and p...   \n",
       "6  I promise you this: I will spare no effort — o...   \n",
       "7  The dreams of too many Americans have been def...   \n",
       "8  With COVID-19 cases rising across the nation, ...   \n",
       "9  I know times are tough, the challenges are dau...   \n",
       "\n",
       "                    mined_at                      created_at  \n",
       "0 2020-12-08 09:45:50.544717  Tue Dec 08 13:56:00 +0000 2020  \n",
       "1 2020-12-08 09:45:50.545715  Tue Dec 08 01:59:00 +0000 2020  \n",
       "2 2020-12-08 09:45:50.545715  Mon Dec 07 21:05:00 +0000 2020  \n",
       "3 2020-12-08 09:45:50.545715  Mon Dec 07 17:45:00 +0000 2020  \n",
       "4 2020-12-08 09:45:50.545715  Mon Dec 07 16:48:01 +0000 2020  \n",
       "5 2020-12-08 09:45:50.545715  Mon Dec 07 15:07:00 +0000 2020  \n",
       "6 2020-12-08 09:45:50.545715  Mon Dec 07 01:30:00 +0000 2020  \n",
       "7 2020-12-08 09:45:50.545715  Sun Dec 06 21:00:00 +0000 2020  \n",
       "8 2020-12-08 09:45:50.545715  Sun Dec 06 16:17:00 +0000 2020  \n",
       "9 2020-12-08 09:45:50.545715  Sun Dec 06 01:16:00 +0000 2020  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the tweets output from tweetminer and converting it into a pandas dataframe\n",
    "# A: Joe Biden\n",
    "\n",
    "pd.DataFrame(biden).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336320843484286977</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>485</td>\n",
       "      <td>...And it’s not normal when a sitting Senator ...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 14:44:51 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336318760106471424</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>4346</td>\n",
       "      <td>I hope House Republicans will vote against the...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 14:36:34 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336177638528983041</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>19322</td>\n",
       "      <td>Georgia is watching @BrianKempGA, @GeoffDuncan...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 05:15:48 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336161955845959680</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>38569</td>\n",
       "      <td>https://t.co/reenwuelHY</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 04:13:29 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1336150611889426433</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>25781</td>\n",
       "      <td>THANK YOU GEORGIA! https://t.co/62s0XaiYPI</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 03:28:25 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1336148836495069185</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>32010</td>\n",
       "      <td>Georgia Lt. Governor @GeoffDuncanGA is a RINO ...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 03:21:21 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1336122354003537921</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>30755</td>\n",
       "      <td>“Georgia is not the only state that pushed thr...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 01:36:07 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1336114633485266944</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>30042</td>\n",
       "      <td>Mail-In rejection rate was minuscule compared ...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 01:05:27 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1336113603116752897</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>28846</td>\n",
       "      <td>State officials were ignorant of the limitatio...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 01:01:21 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1336112582424473600</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>31996</td>\n",
       "      <td>“These actions on the part of State Officials,...</td>\n",
       "      <td>2020-12-08 09:46:00.598633</td>\n",
       "      <td>Tue Dec 08 00:57:18 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           handle  retweet_count  \\\n",
       "0  1336320843484286977  realDonaldTrump            485   \n",
       "1  1336318760106471424  realDonaldTrump           4346   \n",
       "2  1336177638528983041  realDonaldTrump          19322   \n",
       "3  1336161955845959680  realDonaldTrump          38569   \n",
       "4  1336150611889426433  realDonaldTrump          25781   \n",
       "5  1336148836495069185  realDonaldTrump          32010   \n",
       "6  1336122354003537921  realDonaldTrump          30755   \n",
       "7  1336114633485266944  realDonaldTrump          30042   \n",
       "8  1336113603116752897  realDonaldTrump          28846   \n",
       "9  1336112582424473600  realDonaldTrump          31996   \n",
       "\n",
       "                                                text  \\\n",
       "0  ...And it’s not normal when a sitting Senator ...   \n",
       "1  I hope House Republicans will vote against the...   \n",
       "2  Georgia is watching @BrianKempGA, @GeoffDuncan...   \n",
       "3                            https://t.co/reenwuelHY   \n",
       "4         THANK YOU GEORGIA! https://t.co/62s0XaiYPI   \n",
       "5  Georgia Lt. Governor @GeoffDuncanGA is a RINO ...   \n",
       "6  “Georgia is not the only state that pushed thr...   \n",
       "7  Mail-In rejection rate was minuscule compared ...   \n",
       "8  State officials were ignorant of the limitatio...   \n",
       "9  “These actions on the part of State Officials,...   \n",
       "\n",
       "                    mined_at                      created_at  \n",
       "0 2020-12-08 09:46:00.598633  Tue Dec 08 14:44:51 +0000 2020  \n",
       "1 2020-12-08 09:46:00.598633  Tue Dec 08 14:36:34 +0000 2020  \n",
       "2 2020-12-08 09:46:00.598633  Tue Dec 08 05:15:48 +0000 2020  \n",
       "3 2020-12-08 09:46:00.598633  Tue Dec 08 04:13:29 +0000 2020  \n",
       "4 2020-12-08 09:46:00.598633  Tue Dec 08 03:28:25 +0000 2020  \n",
       "5 2020-12-08 09:46:00.598633  Tue Dec 08 03:21:21 +0000 2020  \n",
       "6 2020-12-08 09:46:00.598633  Tue Dec 08 01:36:07 +0000 2020  \n",
       "7 2020-12-08 09:46:00.598633  Tue Dec 08 01:05:27 +0000 2020  \n",
       "8 2020-12-08 09:46:00.598633  Tue Dec 08 01:01:21 +0000 2020  \n",
       "9 2020-12-08 09:46:00.598633  Tue Dec 08 00:57:18 +0000 2020  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B: Donald Trump\n",
    "pd.DataFrame(donald).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "# [3] Create Training Data\n",
    "\n",
    "##### This will be done on the following steps\n",
    "\n",
    "- 1. Convert Tweets output into a dataframe\n",
    "- 2. Merge two dataframes into one\n",
    "- 3. Check ngrams to see interesting word count\n",
    "```\n",
    "____________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joe Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3039, 6)\n"
     ]
    }
   ],
   "source": [
    "# Tweetminer\n",
    "# Max pages=8 because to have almost equal shapes\n",
    "\n",
    "biden_tweets = miner.mine_user_tweets(\"Joebiden\")\n",
    "\n",
    "# Converting to dataframe\n",
    "\n",
    "biden_df = pd.DataFrame(biden_tweets)\n",
    "print (biden_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1991, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweetminer\n",
    "\n",
    "trump_tweets = miner.mine_user_tweets(\"realDonaldTrump\")\n",
    "\n",
    "# Converting to dataframe\n",
    "\n",
    "trump_df = pd.DataFrame(trump_tweets)\n",
    "trump_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the two dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5030, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Biden + Trump dataframe\n",
    "# We're calling the data \"tweets\"\n",
    "\n",
    "tweets = pd.concat([trump_df, biden_df], axis=0).reset_index(drop=True)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the n-grams to see interesting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   \n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91mTwo to Four word sentence\u001b[0m\n",
      "[('joe biden', 104), ('maga https', 81), ('second amendment', 60), ('fake news', 58), ('total endorsement', 57), ('sleepy joe', 56)]\n",
      "___________\n",
      "\u001b[1m\u001b[91mOne word\u001b[0m\n",
      "[('https', 1013), ('biden', 301), ('great', 252), ('vote', 243), ('amp', 207), ('election', 186)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# Using TfidfVectorizer to find ngrams\n",
    "# Range = how many words in a sentence\n",
    "\n",
    "# 2-4 words\n",
    "vect = TfidfVectorizer(ngram_range=(2,5), stop_words='english')\n",
    "# 1 words\n",
    "vect2 = TfidfVectorizer(ngram_range=(1,4), stop_words='english')\n",
    "\n",
    "# Converting all Trump tweets into one string\n",
    "\n",
    "com_words = \"\".join(trump_df['text'])\n",
    "ngrams_sum = vect.build_analyzer()(com_words)\n",
    "ngrams_sum2 = vect2.build_analyzer()(com_words)\n",
    "\n",
    "print(color.BOLD + color.RED+\"Two to Four word sentence\"+ color.END)\n",
    "print(Counter(ngrams_sum).most_common(6))\n",
    "print(\"___________\")\n",
    "print(color.BOLD + color.RED+\"One word\"+ color.END)\n",
    "print(Counter(ngrams_sum2).most_common(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91mTwo to Four word sentence\u001b[0m\n",
      "[('donald trump', 453), ('covid 19', 184), ('president trump', 139), ('health care', 120), ('american people', 112), ('white house', 110)]\n",
      "___________\n",
      "\u001b[1m\u001b[91mOne word\u001b[0m\n",
      "[('https', 2309), ('trump', 803), ('president', 734), ('donald', 454), ('donald trump', 453), ('need', 422)]\n"
     ]
    }
   ],
   "source": [
    "# Using TfidfVectorizer to find ngrams\n",
    "# Range = how many words in a sentence\n",
    "\n",
    "# 2-4 words\n",
    "vect = TfidfVectorizer(ngram_range=(2,5), stop_words='english')\n",
    "# 1 words\n",
    "vect2 = TfidfVectorizer(ngram_range=(1,4), stop_words='english')\n",
    "\n",
    "# Converting all Trump tweets into on string\n",
    "com_words = \"\".join(biden_df['text'])\n",
    "ngrams_sum = vect.build_analyzer()(com_words)\n",
    "ngrams_sum2 = vect2.build_analyzer()(com_words)\n",
    "\n",
    "print(color.BOLD + color.RED+\"Two to Four word sentence\"+ color.END)\n",
    "print(Counter(ngrams_sum).most_common(6))\n",
    "print(\"___________\")\n",
    "print(color.BOLD + color.RED+\"One word\"+ color.END)\n",
    "print(Counter(ngrams_sum2).most_common(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# [4] Using Textacy to pre-process tweets\n",
    "\n",
    "##### This will be done on the following steps\n",
    "- 1. Extract Tweets column as a text list\n",
    "- 2. Use **Textacy** to pre-process tweets\n",
    "```\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy import preprocessing as tp\n",
    "from textacy import vsm\n",
    "import textacy as textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More information about textacy\n",
    "# https://github.com/chartbeat-labs/textacy\n",
    "\n",
    "# Text Pre-processing commands and documentation\n",
    "# https://textacy.readthedocs.io/en/stable/api_reference/text_processing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use textacy to Pre-process text with following functions\n",
    "\n",
    "# 1. Replace all Urls\n",
    "# 2. Remove all accents\n",
    "# 3. Replace Emojis\n",
    "# 4. Replace Currency symbols\n",
    "# 5. Replace hashtags\n",
    "# 6. Replace Phone numbers\n",
    "# 7. Remove punctuations \"!@-—=+#$%’^&*)(/\\;:.,~`\"\n",
    "# 8. Normalize unicode characters in text into canonical forms.\n",
    "\n",
    "# We want to make sure we pass arguments to maintain API and Dict\n",
    "# Converting tweet column from dataframe into a list\n",
    "\n",
    "tweet_text=tweets['text'].values.tolist()\n",
    "\n",
    "# Pre-process\n",
    "\n",
    "clean_text=[tp.normalize.normalize_unicode(tp.remove.remove_punctuation(tp.replace.replace_phone_numbers\n",
    "                              (tp.replace.replace_hashtags\n",
    "                               (tp.replace_currency_symbols\n",
    "                                (tp.replace.replace_emojis\n",
    "                                 (tp.remove.remove_accents\n",
    "                                  (tp.replace.replace_urls(x)))))), marks='?!@-—=+#$%’^&*)(/\\;:.,~`'))for x in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State officials were ignorant of the limitations imposed by the Constitution  Ken Starr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if it's a list\n",
    "# Cleaned Text\n",
    "\n",
    "print(clean_text[8])\n",
    "type(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State officials were ignorant of the limitations imposed by the Constitution. Ken Starr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Text\n",
    "\n",
    "print(tweet_text[8])\n",
    "type(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# [5] Building Model\n",
    "\n",
    "##### This will be done on the following steps \n",
    "- 1. Create a target\n",
    "- 2. TF IDF Vectorizer to vectorize text\n",
    "- 3. Split training and test data\n",
    "- 4. TF IDF Vectorizer to vectorize text\n",
    "- 5. Grid search paramaters\n",
    "- 6. Create a pipeline with multiple models \n",
    "- 7. Bagging classifier\n",
    "- 8. Voting classifier\n",
    "```\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6041749502982108\n"
     ]
    }
   ],
   "source": [
    "# creating target\n",
    "\n",
    "y = tweets['handle'].map(lambda x: 1 if x == 'realDonaldTrump' else 0).values\n",
    "print(max(pd.Series(y).value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Using label Encoder for the target\n",
    "\n",
    "le = LabelEncoder()\n",
    "y2=le.fit_transform(tweets['handle'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5030, 4993)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# TF IDF Vectorizer to vectorize text\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range=(2,4), max_features=4993)\n",
    "cvec = CountVectorizer(ngram_range=(2,4), max_features=4993)\n",
    "X = tfv.fit_transform(clean_text).todense()\n",
    "X2= cvec.fit_transform(clean_text)\n",
    "\n",
    "print (X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5030,)\n"
     ]
    }
   ],
   "source": [
    "print (y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2515, 4993), (2515,), (2515, 4993), (2515,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.50,random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=1,\n",
       "             param_grid={'C': array([1.00000000e-05, 1.12332403e-05, 1.26185688e-05, 1.41747416e-05,\n",
       "       1.59228279e-05, 1.78864953e-05, 2.00923300e-05, 2.25701972e-05,\n",
       "       2.53536449e-05, 2.84803587e-05, 3.19926714e-05, 3.59381366e-05,\n",
       "       4.03701726e-05, 4.53487851e-05, 5.09413801e-05, 5.72236766e-05,\n",
       "       6.42807312e-05, 7.22080902e-05...\n",
       "       6.89261210e-02, 7.74263683e-02, 8.69749003e-02, 9.77009957e-02,\n",
       "       1.09749877e-01, 1.23284674e-01, 1.38488637e-01, 1.55567614e-01,\n",
       "       1.74752840e-01, 1.96304065e-01, 2.20513074e-01, 2.47707636e-01,\n",
       "       2.78255940e-01, 3.12571585e-01, 3.51119173e-01, 3.94420606e-01,\n",
       "       4.43062146e-01, 4.97702356e-01, 5.59081018e-01, 6.28029144e-01,\n",
       "       7.05480231e-01, 7.92482898e-01, 8.90215085e-01, 1.00000000e+00]),\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2'], 'C':np.logspace(-5,0,100)}\n",
    "#Grid searching\n",
    "gs = GridSearchCV(lr, param_grid=params, cv=5, verbose=0,n_jobs=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l2'}\n",
      "0.909741550695825\n"
     ]
    }
   ],
   "source": [
    "print (gs.best_params_)\n",
    "print (gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87075997773612\n",
      "0.6075546719681908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(LogisticRegression(), X_train, y_train, cv=3)\n",
    "\n",
    "print (accuracies.mean())\n",
    "print (1-y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipelines Creation\n",
    "## 1. Data Preprocessing by using Standard Scaler\n",
    "## 2. Apply  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('lr_classifier',LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([('dt_classifier',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm=Pipeline([('svc_classifier',SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb=Pipeline([('xgb_classifier',GradientBoostingClassifier(n_estimators=100, learning_rate=1,\n",
    "                      max_depth=3, random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest, pipeline_svm, pipeline_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest', 3: 'SVM', 4:'xgb'}\n",
    "\n",
    "## Fit the pipelines\n",
    "\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9113320079522863\n",
      "Decision Tree Test Accuracy: 0.8429423459244533\n",
      "RandomForest Test Accuracy: 0.8799204771371769\n",
      "SVM Test Accuracy: 0.8890656063618291\n",
      "xgb Test Accuracy: 0.8500994035785289\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mClassifier with best accuracy:Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   \n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(X_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print(color.BOLD + color.BLUE+'Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(pipeline_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=Pipeline(steps=[('lr_classifier',\n",
       "                                                  LogisticRegression(random_state=42))]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057654075546719"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAccuracy: 0.91 (+/- 0.02) [Logistic Regression]\n",
      "\u001b[1m\u001b[94mAccuracy: 0.85 (+/- 0.02) [Decision Tree]\n",
      "\u001b[1m\u001b[94mAccuracy: 0.88 (+/- 0.03) [RandomForest]\n",
      "\u001b[1m\u001b[94mAccuracy: 0.90 (+/- 0.02) [SVM]\n",
      "\u001b[1m\u001b[94mAccuracy: 0.85 (+/- 0.02) [GradientBoostingClassifier]\n",
      "\u001b[1m\u001b[94mAccuracy: 0.89 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = pipeline_lr\n",
    "clf2 = pipeline_dt\n",
    "clf3 = pipeline_randomforest\n",
    "clf4 = pipeline_svm\n",
    "clf5 = pipeline_xgb\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('dt', clf2), ('rf', clf3), ('svm', clf4), ('gbc', clf5)],)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, eclf], ['Logistic Regression', 'Decision Tree', 'RandomForest', 'SVM', 'GradientBoostingClassifier', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(color.BOLD + color.BLUE+\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to use Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# [6] Highest probablity tweet and Prediction module\n",
    "\n",
    "##### This will be done on the following steps\n",
    "- 1. Testing a prediction module\n",
    "- 2. Create a prediction function\n",
    "- 3. See tweet with highest probability from Biden\n",
    "- 4. See tweet with highest probability from Trump\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proba_Biden</th>\n",
       "      <th>Proba_Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.768084</td>\n",
       "      <td>0.231916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Proba_Biden  Proba_Trump\n",
       "0     0.768084     0.231916"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting into LR\n",
    "\n",
    "estimator = LogisticRegression(penalty='l2',C=1)\n",
    "estimator.fit(X,y2)\n",
    "\n",
    "# Testing TfIdf vectors with copied tweets\n",
    "# First is from Biden\n",
    "\n",
    "source_test = [\n",
    "    \"Paul Sarbanes and I served together on the Foreign Relations Committee for 30 years. There was no one sharper, more committed, or with firmer principles. And he, too, returned to his family nearly every night. They meant the world to him.Rest In Peace, Paul.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Printing results\n",
    "\n",
    "Xtest = tfv.transform(source_test)\n",
    "ac=pd.DataFrame(estimator.predict_proba(Xtest), columns=[\"Proba_Biden\", \"Proba_Trump\"])\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82631523, 0.17368477],\n",
       "       [0.82923373, 0.17076627],\n",
       "       [0.55022047, 0.44977953],\n",
       "       ...,\n",
       "       [0.81040594, 0.18959406],\n",
       "       [0.8110458 , 0.1889542 ],\n",
       "       [0.78267278, 0.21732722]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prediction function\n",
    "# You could a paste a text from a tweet by either candidates and the module will predict to whom it belongs\n",
    "\n",
    "def predict_text() :\n",
    "    \n",
    "    print(color.BOLD +'\"PASTE TWEET TEXT HERE\"'+ color.END)\n",
    "    in_no = [input()]\n",
    "    \n",
    "    \n",
    "    # Text Preprocess\n",
    "    \n",
    "    cleaning=[tp.normalize.normalize_unicode(tp.remove.remove_punctuation(tp.replace.replace_phone_numbers\n",
    "                              (tp.replace.replace_hashtags\n",
    "                               (tp.replace_currency_symbols\n",
    "                                (tp.replace.replace_emojis\n",
    "                                 (tp.remove.remove_accents\n",
    "                                  (tp.replace.replace_urls(x)))))), marks='?!@-—=+#$%’^&*)(/\\;:.,~`'))for x in in_no]\n",
    "    #\n",
    "    \n",
    "    Xtest1 = tfv.transform(cleaning)\n",
    "    pr=pd.DataFrame(estimator.predict_proba(Xtest1), columns=[\"Proba_Biden\", \"Proba_Trump\"])\n",
    "    \n",
    "    # Plotting a bar chart\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,0.5,0.5])\n",
    "    cand = ['Proba_Biden', 'Proba_Trump']\n",
    "    probabilty = [float(pr['Proba_Biden']*100),float(pr['Proba_Trump']*100)]\n",
    "    ax.bar(cand,probabilty)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Answer\n",
    "    \n",
    "    if min(pr) == 'Proba_Biden' :\n",
    "        print(color.BOLD + color.BLUE +\"THIS TWEET IS PROBABLY BY **JOE BIDEN**\"+ color.END)\n",
    "    else:\n",
    "        print (color.BOLD + color.RED +\"THIS TWEET IS PROBABLY BY **DONALD TRUMP**\"+ color.END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\"PASTE TWEET TEXT HERE\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "   All Donald Trump can see from Park Avenue is Wall Street.  He thinks the economy is doing well if the Dow Jones is doing well.  Believe it or not, Mr. President, most Americans don't live off the stock market.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mTHIS TWEET IS PROBABLY BY **JOE BIDEN**\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predict_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most probable tweet from both candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Proba_Biden</th>\n",
       "      <th>Proba_Donald</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336320843484286977</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>638</td>\n",
       "      <td>...And it’s not normal when a sitting Senator ...</td>\n",
       "      <td>2020-12-08 09:46:15.616898</td>\n",
       "      <td>Tue Dec 08 14:44:51 +0000 2020</td>\n",
       "      <td>0.826315</td>\n",
       "      <td>0.173685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336318760106471424</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>4442</td>\n",
       "      <td>I hope House Republicans will vote against the...</td>\n",
       "      <td>2020-12-08 09:46:15.616898</td>\n",
       "      <td>Tue Dec 08 14:36:34 +0000 2020</td>\n",
       "      <td>0.829234</td>\n",
       "      <td>0.170766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336177638528983041</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>19332</td>\n",
       "      <td>Georgia is watching @BrianKempGA, @GeoffDuncan...</td>\n",
       "      <td>2020-12-08 09:46:15.616898</td>\n",
       "      <td>Tue Dec 08 05:15:48 +0000 2020</td>\n",
       "      <td>0.550220</td>\n",
       "      <td>0.449780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336161955845959680</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>38584</td>\n",
       "      <td>https://t.co/reenwuelHY</td>\n",
       "      <td>2020-12-08 09:46:15.616898</td>\n",
       "      <td>Tue Dec 08 04:13:29 +0000 2020</td>\n",
       "      <td>0.878435</td>\n",
       "      <td>0.121565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1336150611889426433</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>25785</td>\n",
       "      <td>THANK YOU GEORGIA! https://t.co/62s0XaiYPI</td>\n",
       "      <td>2020-12-08 09:46:15.616898</td>\n",
       "      <td>Tue Dec 08 03:28:25 +0000 2020</td>\n",
       "      <td>0.861343</td>\n",
       "      <td>0.138657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           handle  retweet_count  \\\n",
       "0  1336320843484286977  realDonaldTrump            638   \n",
       "1  1336318760106471424  realDonaldTrump           4442   \n",
       "2  1336177638528983041  realDonaldTrump          19332   \n",
       "3  1336161955845959680  realDonaldTrump          38584   \n",
       "4  1336150611889426433  realDonaldTrump          25785   \n",
       "\n",
       "                                                text  \\\n",
       "0  ...And it’s not normal when a sitting Senator ...   \n",
       "1  I hope House Republicans will vote against the...   \n",
       "2  Georgia is watching @BrianKempGA, @GeoffDuncan...   \n",
       "3                            https://t.co/reenwuelHY   \n",
       "4         THANK YOU GEORGIA! https://t.co/62s0XaiYPI   \n",
       "\n",
       "                    mined_at                      created_at  Proba_Biden  \\\n",
       "0 2020-12-08 09:46:15.616898  Tue Dec 08 14:44:51 +0000 2020     0.826315   \n",
       "1 2020-12-08 09:46:15.616898  Tue Dec 08 14:36:34 +0000 2020     0.829234   \n",
       "2 2020-12-08 09:46:15.616898  Tue Dec 08 05:15:48 +0000 2020     0.550220   \n",
       "3 2020-12-08 09:46:15.616898  Tue Dec 08 04:13:29 +0000 2020     0.878435   \n",
       "4 2020-12-08 09:46:15.616898  Tue Dec 08 03:28:25 +0000 2020     0.861343   \n",
       "\n",
       "   Proba_Donald  \n",
       "0      0.173685  \n",
       "1      0.170766  \n",
       "2      0.449780  \n",
       "3      0.121565  \n",
       "4      0.138657  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Probas_x = pd.DataFrame(estimator.predict_proba(X_test), columns=[\"Proba_Biden\", \"Proba_Donald\"])\n",
    "joined_x = pd.merge(tweets, Probas_x, left_index=True, right_index=True)\n",
    "joined_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joe Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m Melanie, thank you for sharing your story and for the sacrifices you've made to keep us all safe. They are not in vain.\n",
      "\n",
      "On Tuesday, we need to vote out Donald Trump and treat the climate crisis like the existential threat it is. https://t.co/dCKIBGlmoo\n"
     ]
    }
   ],
   "source": [
    "# Seeing the tweet with Lowest probabilty from Joe Biden\n",
    "\n",
    "# Tweet\n",
    "\n",
    "joined_Biden = joined_x[joined_x['handle']==\"JoeBiden\"]\n",
    "for el1 in joined_Biden[joined_Biden['Proba_Biden']== max(joined_Biden['Proba_Biden'])]['text']:\n",
    "    print (color.BOLD + color.BLUE, el1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m All Donald Trump can see from Park Avenue is Wall Street.\n",
      "\n",
      "He thinks the economy is doing well if the Dow Jones is doing well.\n",
      "\n",
      "Believe it or not, Mr. President, most Americans don't live off the stock market.\n"
     ]
    }
   ],
   "source": [
    "# Seeing the tweet with Highest probabilty from Joe Biden\n",
    "\n",
    "# Tweet\n",
    "\n",
    "\n",
    "for el3 in joined_Biden[joined_Biden['Proba_Biden']== min(joined_Biden['Proba_Biden'])]['text']:\n",
    "    print (color.BOLD + color.DARKCYAN, el3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m Claudia Tenney is GREAT. Loves New York &amp; USA. She has my Full &amp; Complete Endorsement! VOTE https://t.co/30sGVdMDLu\n"
     ]
    }
   ],
   "source": [
    "# Seeing the tweet with Lowest probabilty from Donald Trump\n",
    "\n",
    "# Tweet\n",
    "\n",
    "joined_donald = joined_x[joined_x['handle']==\"realDonaldTrump\"]\n",
    "for el in joined_donald[joined_donald['Proba_Donald']==max(joined_donald['Proba_Donald'])]['text']:\n",
    "    print (color.BOLD + color.BLUE,el)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m Ammar is a puppet for Nancy Pelosi and the Radical Left. He spells higher taxes, weak Military and Vet support, and the obliteration of your 2nd Amendment. Vote Darrell Issa! https://t.co/0nwCTVWPh3\n"
     ]
    }
   ],
   "source": [
    "# Seeing the tweet with Highest probabilty from Donald Trump\n",
    "\n",
    "# Tweet\n",
    "\n",
    "\n",
    "joined_donald = joined_x[joined_x['handle']==\"realDonaldTrump\"]\n",
    "for el in joined_donald[joined_donald['Proba_Donald']==min(joined_donald['Proba_Donald'])]['text']:\n",
    "    print (color.BOLD + color.DARKCYAN,el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
